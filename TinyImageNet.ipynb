{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyImageNetDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.image_paths, self.labels = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "\n",
    "        if self.split == 'train_':\n",
    "            # Load train data\n",
    "            train_dir = os.path.join(self.root_dir,train)\n",
    "            class_folders = os.listdir(train_dir)\n",
    "            for class_folder in class_folders:\n",
    "                class_path = os.path.join(train_dir, class_folder)\n",
    "                image_files = os.listdir(class_path)\n",
    "                image_files = [path for path in image_files if not path.endswith('.txt')]\n",
    "                for image_file in image_files:\n",
    "                    image_paths.append(os.path.join(class_path, image_file))\n",
    "                    labels.append(class_folder)\n",
    "\n",
    "        elif self.split == 'test_':\n",
    "            # Load test data\n",
    "            test_dir = os.path.join(self.root_dir,'test','images')\n",
    "            image_files = os.listdir(test_dir)\n",
    "            for image_file in image_files:\n",
    "                image_paths.append(image_file)\n",
    "                labels.append(None)  \n",
    "\n",
    "        elif self.split == 'val_':\n",
    "            # Load validation data\n",
    "            val_dir = os.path.join(self.root_dir,'val')\n",
    "\n",
    "            image_dir = os.path.join(val_dir,'images')\n",
    "            img_files = os.listdir(image_dir)\n",
    "            for image_file in img_files:\n",
    "                image_paths.append(image_file)\n",
    "            \n",
    "            annotation_file = os.path.join(val_dir,'val_annotations.txt')\n",
    "            annotations_df = pd.read_csv(annotation_file, sep='\\t', header=None)\n",
    "            for _, row in annotations_df.iterrows():\n",
    "                image_paths.append(os.path.join(val_dir, row[0]))\n",
    "                labels.append(row[1])\n",
    "\n",
    "        return image_paths, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.split, self.image_paths[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = TinyImageNetDataset(root_dir='F:\\\\Research\\\\tiny-imagenet-200', split='train_', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = TinyImageNetDataset(root_dir='F:\\\\Research\\\\tiny-imagenet-200', split='test_', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset = TinyImageNetDataset(root_dir='F:\\\\Research\\\\tiny-imagenet-200', split='val_', transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TinyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3 * 224 * 224, 128)\n",
    "        self.fc2 = nn.Linear(128, 200)  # 10 classes for CIFAR-10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten input\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = TinyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def train_one_epoch():\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    train_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()  \n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_samples += len(labels)\n",
    "\n",
    "    average_loss = total_loss / total_samples\n",
    "    return average_loss\n",
    "\n",
    "\n",
    "def plot_losses(train_losses, test_losses):\n",
    "    plt.plot(range(len(train_losses)), train_losses, label='Train Loss')\n",
    "    plt.plot(range(len(test_losses)), test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(100):\n",
    "    train_loss = train_one_epoch()  \n",
    "    test_loss = validate(model, val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "plot_losses(train_losses, test_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
